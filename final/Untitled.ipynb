{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "1. INTRODUCTION\n",
    "\n",
    "In this section, orient your readers to your project. You've already written some of these in previous deliverables. Based on your final analysis, revise your problem statement and write a concise introduction section. This section should touch upon the following points, but should be written in full paragraphs. Your writing should incorporate all of these points (and more if you like) in a coherent way. Remember that you are trying to convince your readers that this is an important problem to tackle.\n",
    "Problem Statement\n",
    "Describe the problem you would like to tackle.\n",
    "What is the topic of your project?\n",
    "What do you want to learn about it?\n",
    "\n",
    "We want to create a proof of concept project that would allow us to convert laser drawn writing into digit representations. Through the completion of this endeavour we would have gained an in-depth exposure to python ski-kit lean’s utilities, have a greater understanding of using data sets to train models to recognize patterns such as handwriting, and achieve a comprehensive understanding of other python libraries such as image processing and pixel analysis. \n",
    "\n",
    "Significance of the Problem\n",
    "Why is it important to tackle this problem in your project?\n",
    "In what ways could the insights from this project be useful?\n",
    "Has there been previous work on your topic? Do some research into your topic. Cite your sources appropriately. You can use the numbered reference format or APA (if you are more comfortable with it).\n",
    "This project serves as a proof of concept regarding the futuristic ability of medium translation from lasers to understandable text. Having a constant stream of data being read from a laser pointer and translated onto a screen not only greatly studies data science, machine learning, and image processing libraries, but will create an incredibly interesting project that can be constantly tweaked and improved. For example, one can extend the laser translation functionality to incorporate deciphering more than just digits - including symbols, shapes, and letters - and potentially bring light to a unique form of discrete communication. \n",
    "There has been no recorded research on our particular laser to text proposal. However, digit recognition is an incredibly widely researched subject, and one that many continue to discover new applications for [1]. We believe that our project signifies the creation of just one more of these useful applications.\n",
    "1. Team, D. F. (2020, January 7). Deep Learning Project - Handwritten Digit Recognition using\n",
    "Python. Retrieved from \n",
    "https://data-flair.training/blogs/python-deep-learning-project-handwritten-digit-recognition\n",
    "\n",
    "Questions/Hypothesis\n",
    "End this section with a list of questions and hypotheses\n",
    "You should tie these questions/hypotheses to the problem statement and its significance\n",
    "e.g. Given the aforementioned problem and its importance, we set out to tackle the following questions:\n",
    "\n",
    "Given the aforementioned problem and its importance, we set out to tackle the following questions:\n",
    "Q1: Is the accuracy of our tests dependent on the robustness of our image stitching code or rather the model?\n",
    "Q2: Will the speed of our laser drawn digit result in greater inaccuracy of digit prediction? (Requirement 2: variable question)\n",
    "Q3: Due the incredible size of the data set, what is the optimal algorithm and what are the most effective parameters for this algorithm, e.g., choosing the number of iterations, error tolerance, etc.?\n",
    "We believe that the accuracy will be dependent on the color of laser used and the color of the background wall as well - making these decisions integral in guaranteeing success. In order to prove this, we will run our program through different wall backgrounds and analyze the implications of each.\n",
    "Our hypothesis is that the accuracy of our tests will be fully determined by how robust our image stitching (i.e. the process that takes the parsed video images and re-constitutes a composite image by analyzing the points in each image with the greatest color contrast) code proves to be - as opposed to it being an issue on the model’s side. Our workflow will be to capture a video of someone outlining a digit with a laser pointer, splitting this video into various images each with their own laser location, stitching all of these images back together to form a singular number made up of various laser point locations, feeding this data into our digit-recognizer model, and finally printing this number.  Thus, our hypothesis is that the accuracy of this methodology will ultimately define the accuracy of our model and code as a whole. \n",
    "\tFurthermore, we believe that the speed of the drawing will be a determining factor regarding the ultimate prediction accuracy of the drawn digit. Since we will be parsing the video drawing by frames, it would make sense that writer slower equates more accurate results.\n",
    "\tSince numbers have a high variance we have a very large dataset, we hypothesis that the KNN algorithm will provide the most optimal results. Furthermore, the large number of features usually bogs down many accuracy algorithms and and makes training time unfeasibly long. This is the case with LinearSVC and not the case with KNN, so we have further reason to believe that KNN will be an optimal algorithm choice.\n",
    "\n",
    "\n",
    "\n",
    "…..\n",
    "\n",
    "*Side note regarding question requirements - Our feature variables are 784 pixels, and in of themselves, they don’t have any particular meaning. For example, in a heart disease prediction machine project - one could draw hypotheses based on a single variable (e.g. body-fat percentage) and what they believe its impact will be on the result. For our case, variable-based questions will have to reference outside factors such as speed of drawing, color of background, etc, since a single pixel density does not provide insight in of itself.  \n",
    "--------------------------------------------------------------------\n",
    "2. METHOD\n",
    "2.1. Data Acquisition\n",
    "Describe where you obtained your data. Provide a link to the original source.\n",
    "\n",
    "Training data: kaggle.com/c/digit-recognizer/download/G4erCQmLsLsmveFfJfNg%2Fversions%2FFy8gTgxUjCWjkk6UfEsa%2Ffiles%2Ftrain.csv\n",
    "Testing data: kaggle.com/c/digit-recognizer/download/G4erCQmLsLsmveFfJfNg%2Fversions%2FFy8gTgxUjCWjkk6UfEsa%2Ffiles%2Ftest.csv\n",
    "\n",
    "If you scraped your data, include your code as a separate script file \n",
    "NA\n",
    "Your data should be stored in an online repository (e.g., GitHub) and your code should retrieve your data from that online resource. You can read csv files from the Web in the same way that you read files from a local drive.\n",
    "???\n",
    "Describe the dataset and variables. What do variables represent?\n",
    "The dataset contains 28,000 digit image representations ranging from 1 through 9 - each represented through a collection of 784 pixel values labeled pixel0, pixel1..pixel783. Each pixel variable provides a grayscale value (ranging from 0 to 255) that makes up the image. By taking one of these 784 long pixel series, reshaping it into a 28x28 image, and plotting the data through pyplot, the image representation of the digit is created. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2.2. Variables\n",
    "For your hypotheses, what are your IVs and DVs?\n",
    "For your predictive models, what are your features and target variables?\n",
    "2.3. Data Analysis\n",
    "Specifically describe your predictive model. What outcome variable are you going to predict from what feature variables?\n",
    "Describe whether this is a supervised or unsupervised learning problem. Also identify the sub-category of the learning task (e.g. classification).\n",
    "What machine learning algorithms are you going to use? Why?\n",
    "\n",
    "The machine learning algorithm we chose and used for our model was the KNN algorithm. We chose this algorithm for the following  reasons:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. RESULTS\n",
    "3.1. Data Wrangling\n",
    "When training the model, we already had well formed data in a csv format that we could just read into a dataframe and train and test the model on. However, using the model with the rest of our workflow, we had to ultimately convert a video to a dataframe with 784 columns with each number in the column ranging from 0-255 where 255 is darkest and 0 is lightest, as that was the type of input the model needed. Doing this required extensive data wrangling. \n",
    "To start off, we have a video of us drawing with a laser. We want to convert this to what represents an image of a digit. First, we have to split the video into frames and convert all of them into one image. Each frame shows the laser’s dot on the wall at a given time. So, to get the image of the digit we have to essentially overlay the laser point in each frame onto the final composite frame. To do this, we resize each frame so thats its 28 * 28 pixels (this is 784 pixels in totals like how the model expects). \n",
    "Then we get the pixel array of the image (a list of 784 items that range from 0-1, where 1 is darkest and 0 is lightest). To figure out the location of the laser point in that frame, we have a threshold: A green laser typically has a brightness less than .15, so we gather the locations of the pixels that are below that threshold and return them. These locations will be marked on the final composite pixel array as 255 (darkest) to mark where the laser’s point was.\n",
    "After this process is done on every frame, the final composite pixel array has values 255 for every location the laser was, and 0 for all the other values. This array represents the digit. Finally, we convert it into a dataframe and pass it the model for prediction.\n",
    "3.2. Data Exploration\n",
    "Generate appropriate data visualizations for your key variables identified in the previous section\n",
    "You should have at least three visualizations (and at least two different visualization types)\n",
    "For each visualization provide an explanation regarding the variables involved and an interpretation of the graph.\n",
    "If you are using Plotly, insert your visualizations as images as well (upload the graph images to an online source, e.g. github, and link those in Jupyter Notebook)\n",
    "3.3. Model Construction\n",
    "If you proposed hypotheses, conduct your hypothesis tests\n",
    "For your machine learning question(s), split data into training, validation, and testing sets (or use cross-validation)\n",
    "Apply machine learning algorithms (apply at least three algorithms)\n",
    "Train your algorithms\n",
    "3.4. Model Evaluation\n",
    "Evaluate the performance of your algorithms on appropriate evaluation metrics, using your validation set\n",
    "Interpret your results from multiple models (and hypothesis tests, if any)\n",
    "3.5. Model Optimization\n",
    "Tune your models using appropriate hyperparameters\n",
    "Explain why you are doing this (e.g., to avoid overfitting, etc.)\n",
    "3.6. Model Testing\n",
    "Test your tuned algorithms using your testing set\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "4. DISCUSSION\n",
    "Provide a summary of the steps you took to analyze your data and test your predictive model\n",
    "Interpret your findings from 3.4., 3.5, and 3.6\n",
    "Which algorithms did you compare?\n",
    "- Decision Tree algorithm\n",
    "- LinearSVC\n",
    "- GaussianNb\n",
    "- KneighborsClassifier\n",
    "- SVC\n",
    "Which algorithm(s) revealed best performance?\n",
    "The KNN algorithm (KneighborsClassifier) revealed the best performance.\n",
    "\n",
    "\n",
    "Which algorithm(s) should be used for your predictive model?\n",
    "The KNN algorithm (KneighborsClassifier) should be used for our predictive model.\n",
    "\n",
    "If you tested hypotheses, interpret the results. What does it mean to have significant/non-significant differences with regards to your data?\n",
    "\n",
    "\n",
    "\n",
    "End this section with a conclusion paragraph containing some pointers for future work *(e.g., get more data, perform another analysis, etc.)\n",
    " \n",
    "--------------------------------------------------------------------\n",
    "CONTRIBUTIONS\n",
    "Tushar: Worked on the image processing pipeline/orchestration and image stitching.\n",
    "Zumaad: Worked on the image processing pipeline/orchestration and image stitching.\n",
    "Srinath: worked on model construction, evaluation and visualization.\n",
    "Eric: worked on the conversion from video into frames with variable frame speeds.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
